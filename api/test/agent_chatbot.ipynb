{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.57.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder_1 = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenRouter API integration\n",
    "class OpenRouterModel:\n",
    "    def __init__(self, model_name: str, api_key: str):\n",
    "        self.base_url = \"https://openrouter.ai/api/v1\"\n",
    "        self.model_name = model_name,\n",
    "        self.api_key = api_key\n",
    "\n",
    "\n",
    "    def invoke(self, messages: list):\n",
    "        # Prepare request payload\n",
    "        # payload = {\n",
    "        #     \"model\": self.model_name,\n",
    "        #     \"messages\": messages,\n",
    "        #     \"max_tokens\": 1024,\n",
    "        #     \"temperature\": 0.7\n",
    "        # }\n",
    "\n",
    "        client = OpenAI(\n",
    "            base_url=self.base_url,\n",
    "            api_key=self.api_key,\n",
    "        )\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        # Send request\n",
    "        return completion.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenRouter model\n",
    "openrouter_model = OpenRouterModel(\n",
    "    model_name=\"microsoft/phi-3-mini-128k-instruct:free\",\n",
    "    api_key=\"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\"  # Replace with your actual OpenRouter API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eb3ada0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "\n",
    "# def chatbot(state: State):\n",
    "#     return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "# Define chatbot function\n",
    "def chatbot(state: State):\n",
    "    # Invoke the OpenRouter model\n",
    "    response = openrouter_model.invoke(state[\"messages\"])\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "    return state\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder_1.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eb3ada0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder_1.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eb3ada0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder_1.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder_1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm happy to chat with you! However, I don't see a specific question or topic you'd like to discuss. Would you like to:\n",
      "\n",
      "1. Ask a question?\n",
      "2. Share your thoughts or feelings about something?\n",
      "3. Discuss a particular topic, such as a hobby, movie, or book?\n",
      "4. Play a game or engage in a fun conversation?\n",
      "\n",
      "Let me know, and I'll do my best to assist you!\n",
      "Assistant: LangGraph! LangGraph is a fascinating open-source project that has gained significant attention in the natural language processing (NLP) and artificial intelligence (AI) communities. From what I know, LangGraph is a large-scale, multilingual language model that aims to integrate multiple language understanding and generation capabilities into a single, unified graph-based framework.\n",
      "\n",
      "Here are some key features and advantages of LangGraph:\n",
      "\n",
      "1. **Multilingual capability**: LangGraph supports over 100 languages, making it a powerful tool for cross-lingual language understanding and generation tasks.\n",
      "2. **Graph-based architecture**: LangGraph represents language as a graph, where nodes and edges symbolize linguistic elements, such as words, phrases, and dependencies. This architecture enables more efficient and flexible processing of complex language structures.\n",
      "3. **Integrated language understanding and generation**: LangGraph combines both language understanding (e.g., question answering, sentiment analysis) and generation (e.g., text summarization, language translation) capabilities in a single model.\n",
      "4. **Scalability and adaptability**: LangGraph's graph-based architecture allows it to scale more efficiently than traditional sequence-based models, making it suitable for large-scale NLP applications.\n",
      "5. **Open-source and community-driven**: LangGraph is open-source, which enables researchers and developers to contribute to its development, experiment with new ideas, and apply it to various use cases.\n",
      "\n",
      "Some potential applications of LangGraph include:\n",
      "\n",
      "1. **Multilingual chatbots and conversational AI**: LangGraph can enable chatbots to understand and respond to user queries in multiple languages, facilitating more effective cross-cultural communication.\n",
      "2. **Cross-lingual language translation and localization**: LangGraph's multilingual capability makes it suitable for large-scale language translation and localization tasks, such as translating websites, documents, or subtitles.\n",
      "3. **Language understanding and sentiment analysis**: LangGraph can be used for sentiment analysis, question answering, and other language understanding tasks across multiple languages and domains.\n",
      "\n",
      "While LangGraph is still an emerging technology, its potential to revolutionize the field of NLP and AI is substantial. I'm excited to see how researchers and developers will continue to build upon and apply LangGraph in the future!\n",
      "\n",
      "Do you have any specific questions about LangGraph or its applications?\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
    "    }):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1][\"content\"])\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.57.2-py3-none-any.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m383.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: sniffio in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/vihidun/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-1.57.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The meaning of life is a question that has intrigued philosophers, theologians, scientists, and countless individuals throughout human history. It is inherently a subjective question, with answers varying significantly based on personal beliefs, cultural values, philosophical viewpoints, and religious teachings. Broadly speaking, various interpretations of the meaning of life include:\n",
      "\n",
      "\n",
      "1. **Biological Perspective**: From a biological standpoint, one could argue that the meaning of life could lie in the continuation of species and genetic code through procreation, which ensures the survival and evolution of one's lineage.\n",
      "\n",
      "\n",
      "2. **Existential View**: Existentialists suggest that life inherently has no predefined meaning, but individuals can create their own meaning through their choices, actions, and commitments.\n",
      "\n",
      "\n",
      "3. **Philosophical Inquiry**: Immanuel Kant proposed pursuing knowledge and happiness as the ultimate purposes of human life. In his view, ethical living guided by reason and autonomy conveys the meaning.\n",
      "\n",
      "\n",
      "4. **Religious Beliefs**: Many religions posit that life's meaning is found in living according to divine laws and principles, striving for spiritual enlightenment, performing good deeds, or achieving a favorable afterlife.\n",
      "\n",
      "\n",
      "5. **Psychological Theory**: Carl Jung, for instance, believed that the meaning of life could be discovered through the individuation process, which is the journey toward wholeness and the realization of one's full potential.\n",
      "\n",
      "\n",
      "Ultimately, the meaning of life may require deep self-reflection, learning, and experiences with others, as well as an appreciation for the complexity and diversity of human perspectives.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"microsoft/phi-3-mini-128k-instruct:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is the meaning of life?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"google/gemini-2.0-flash-exp:free\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client_mistral = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_response_mistral(prompt):\n",
    "    completion = client_mistral.chat.completions.create(\n",
    "        model=\"mistralai/mistral-7b-instruct:free\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client_phi = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_response_phi(prompt):\n",
    "    completion = client_phi.chat.completions.create(\n",
    "        model=\"microsoft/phi-3-medium-128k-instruct:free\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client_learnlm = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_response_learnlm(prompt):\n",
    "    completion = client_learnlm.chat.completions.create(\n",
    "        model=\"google/learnlm-1.5-pro-experimental:free\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate_followup_question(student_question):\n",
    "    prompt = (\n",
    "        \"\"\"You are a Socratic tutor. This is the student question: '{student_question}'.\n",
    "Please generate **an appropriate number of follow-up questions**, each with an expected answer, to guide the student to the correct answer.\n",
    "Only generate the number of questions and answers that are necessary, up to a maximum of 10.\n",
    "If fewer questions are sufficient, stop at the appropriate point.\n",
    "\n",
    "Output the follow-up questions and their expected answers in **valid JSON format** like this:\n",
    "\n",
    "{{\n",
    "    \"questions_and_answers\": [\n",
    "        {{\"question\": \"What is the first step in solving the equation?\",\n",
    "          \"answer\": \"Isolate the variable by subtracting 3 from both sides.\"}},\n",
    "        {{\"question\": \"Can you identify the terms?\",\n",
    "          \"answer\": \"The terms are 2x and 3 on the left side of the equation.\"}},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Ensure the output is **valid JSON**, not truncated, and contains an appropriate number of questions and their corresponding expected answers, based on the complexity of the student's question.\"\"\"\n",
    "    ).format(student_question=student_question)\n",
    "\n",
    "    input_text = generate_response(prompt)\n",
    "\n",
    "    # Extract only the JSON part (everything between the curly braces)\n",
    "    start_index = input_text.find('{')\n",
    "    end_index = input_text.rfind('}') + 1\n",
    "\n",
    "    json_text = input_text[start_index:end_index]\n",
    "\n",
    "    # Convert the extracted JSON string to a Python dictionary\n",
    "    try:\n",
    "        json_object = json.loads(json_text)\n",
    "        return(json_object)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return(f\"Error parsing JSON: {e}\")\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "followup_qa = generate_followup_question(\"It has been estimated that it will take 10 men 6 days to complete a certain task. Find the number of days it will take 8 men to complete a job which is double that task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'questions_and_answers': [{'question': 'If 10 men take 6 days to complete a task, how many man-days are required to complete the task?', 'answer': '10 men * 6 days = 60 man-days'}, {'question': 'The new job is double the original task. How many man-days are required for the new job?', 'answer': '60 man-days * 2 = 120 man-days'}, {'question': 'If 8 men are working on the new task, and the new task requires 120 man-days, how many days will the work take?', 'answer': '120 man-days / 8 men = 15 days'}]}\n"
     ]
    }
   ],
   "source": [
    "print(followup_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_and_answers = followup_qa[\"questions_and_answers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': \"In the equation 2x + 3 = 5, what is our goal when we are 'solving for x'?\", 'answer': 'To get x by itself on one side of the equation.'}, {'question': \"What operation is currently being performed on the 'x' term that makes it not alone?\", 'answer': 'There is multiplication by 2 and addition of 3 occurring.'}, {'question': \"Which operation (+ or *) should we 'undo' first? Remember, we think about this in reverse order as normal algebraic evaluation. \", 'answer': \"We should 'undo' the addition by subtracting 3 first.\"}, {'question': 'If you subtract 3 from the left side of the equation, what must you also do to the right of the equals sign to keep the equation balanced?', 'answer': 'You must also subtract 3 from the right side.'}, {'question': 'After subtracting 3 from both sides, what is the new equation?', 'answer': '2x = 2'}, {'question': \"What operation is now being performed on 'x'?\", 'answer': 'Multiplication by 2 is occurring.'}, {'question': \"How would we 'undo' multiplication by 2?\", 'answer': 'We would divide by 2.'}, {'question': 'If you divide the left side by 2, what also needs to occur on the right side of the equation?', 'answer': 'You must also divide the right side by 2.'}, {'question': 'What is the final solution for x?', 'answer': 'x = 1'}]\n"
     ]
    }
   ],
   "source": [
    "print(questions_and_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in questions_and_answers:\n",
    "#         question = item.get(\"question\")\n",
    "#         expected_answer = item.get(\"answer\")\n",
    "\n",
    "#         print(\"Question:\", question)\n",
    "#         print(\"Expected Answer:\", expected_answer)\n",
    "#         print(\"--------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in questions_and_answers:\n",
    "#         question = item.get(\"question\")\n",
    "#         expected_answer = item.get(\"answer\")\n",
    "\n",
    "#         if not question or not expected_answer:\n",
    "#             print(\"Invalid question-answer pair. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         # Ask the question in a tutor tone\n",
    "#         # tutor_question = ask_question_in_tutor_tone(question)\n",
    "#         print(\"Follow-up Question:\", question)\n",
    "#         print(\"Expected Answer:\", expected_answer)\n",
    "#         print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_answer_prompt(question, expected_answer, user_answer):\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        You are an AI that checks answers for correctness.\n",
    "\n",
    "        - The question is: \"{question}\"\n",
    "        - The expected answer is: \"{expected_answer}\"\n",
    "        - The user's answer is: \"{user_answer}\"\n",
    "\n",
    "        Based on the user's answer compared to the expected answer, determine if the user's answer is **correct** or **incorrect**.\n",
    "\n",
    "        Output only in valid JSON format like this:\n",
    "\n",
    "        {{\n",
    "            \"result\": \"correct\"  # or \"incorrect\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "    ).format(question=question, expected_answer=expected_answer, user_answer=user_answer)\n",
    "    response = generate_response_mistral(prompt)\n",
    "\n",
    "    input_text = response\n",
    "    # Extract only the JSON part (everything between the curly braces)\n",
    "    start_index = input_text.find('{')\n",
    "    end_index = input_text.rfind('}') + 1\n",
    "\n",
    "    json_text = input_text[start_index:end_index]\n",
    "\n",
    "    # Convert the extracted JSON string to a Python dictionary\n",
    "    try:\n",
    "        json_object = json.loads(json_text)\n",
    "        print(json_object)\n",
    "        return(json_object)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return(f\"Error parsing JSON: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_in_tutor_tone(question):\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "You are a helpful tutor. Ask the following question in a concise, teacher-like tone, encouraging them to think critically but keeping the question short:\n",
    "\n",
    "The question is: \"{question}\"\n",
    "\n",
    "Make sure the phrasing is supportive, but the question is brief and to the point.\n",
    "\"\"\"\n",
    "    ).format(question=question)\n",
    "    return generate_response_phi(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # for item in questions_and_answers:\n",
    "    #     question = item.get(\"question\")\n",
    "    #     expected_answer = item.get(\"answer\")\n",
    "\n",
    "    #     if not question or not expected_answer:\n",
    "    #         print(\"Invalid question-answer pair. Skipping.\")\n",
    "    #         continue\n",
    "\n",
    "    #     # Ask the question in a tutor tone\n",
    "    #     # tutor_question = ask_question_in_tutor_tone(question)\n",
    "    #     print(\"Follow-up Question:\", question)\n",
    "    #     print(\"Expected Answer:\", expected_answer)\n",
    "\n",
    "    #     attempt = 0\n",
    "    #     while attempt < 3:\n",
    "    #         user_answer = input(\"Your Answer: \")\n",
    "    #         print(user_answer)\n",
    "    #         # Check answer correctness\n",
    "    #         result = check_answer_prompt(question, expected_answer, user_answer)\n",
    "    #         if isinstance(result, str):\n",
    "    #             print(\"Error in checking answer:\", result)\n",
    "    #             break\n",
    "\n",
    "    #         is_correct = result.get(\"result\") == \"correct\"\n",
    "    #         print(\"is_correct:\", is_correct)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tutor_with_guidance(correct_answer, student_answer):\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "    The correct answer is: '{correct_answer}'. The student's answer is: '{student_answer} which is incorrect'.\n",
    "\n",
    "    Based on the student's answer and its correctness, provide steps to get the correct answer.\n",
    "\n",
    "    Use a friendly, encouraging tone in your responses. Make sure to keep your response in short.\n",
    "    \"\"\"\n",
    "    ).format(question=question, correct_answer=correct_answer, student_answer=student_answer)\n",
    "    return generate_response_learnlm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has been estimated that it will take 10 men 6 days to complete a certain task. Find the number of days it will take 8 men to complete a job which is double that task.\n",
      "Student Question: It has been estimated that it will take 10 men 6 days to complete a certain task. Find the number of days it will take 8 men to complete a job which is double that task.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(student_question)\n\u001b[0;32m---> 59\u001b[0m \u001b[43msocratic_tutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_question\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36msocratic_tutor\u001b[0;34m(student_question)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent Question:\u001b[39m\u001b[38;5;124m\"\u001b[39m, student_question)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate follow-up questions and expected answers\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m followup_qa \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_followup_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(followup_qa, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in generating follow-up questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, followup_qa)\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mgenerate_followup_question\u001b[0;34m(student_question)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_followup_question\u001b[39m(student_question):\n\u001b[1;32m      4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"You are a Socratic tutor. This is the student question: '{student_question}'.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mPlease generate **an appropriate number of follow-up questions**, each with an expected answer, to guide the student to the correct answer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mEnsure the output is **valid JSON**, not truncated, and contains an appropriate number of questions and their corresponding expected answers, based on the complexity of the student's question.\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\u001b[38;5;241m.\u001b[39mformat(student_question\u001b[38;5;241m=\u001b[39mstudent_question)\n\u001b[0;32m---> 25\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Extract only the JSON part (everything between the curly braces)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m input_text\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(prompt):\n\u001b[1;32m      9\u001b[0m     completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/gemini-2.0-flash-exp:free\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         ]\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def socratic_tutor(student_question):\n",
    "    print(\"Student Question:\", student_question)\n",
    "\n",
    "    # Generate follow-up questions and expected answers\n",
    "    followup_qa = generate_followup_question(student_question)\n",
    "    if isinstance(followup_qa, str):\n",
    "        print(\"Error in generating follow-up questions:\", followup_qa)\n",
    "        return\n",
    "\n",
    "    questions_and_answers = followup_qa.get(\"questions_and_answers\", [])\n",
    "    print(\"Questions and Answers:\", questions_and_answers)\n",
    "    if not questions_and_answers:\n",
    "        print(\"No follow-up questions generated. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for item in questions_and_answers:\n",
    "        question = item.get(\"question\")\n",
    "        expected_answer = item.get(\"answer\")\n",
    "\n",
    "        if not question or not expected_answer:\n",
    "            print(\"Invalid question-answer pair. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Ask the question in a tutor tone\n",
    "        tutor_question = ask_question_in_tutor_tone(question)\n",
    "        print(\"Follow-up Question:\", tutor_question)\n",
    "        print(\"Expected Answer:\", expected_answer)\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < 3:\n",
    "            user_answer = input(\"Your Answer: \")\n",
    "            print(user_answer)\n",
    "            # Check answer correctness\n",
    "            result = check_answer_prompt(question, expected_answer, user_answer)\n",
    "            if isinstance(result, str):\n",
    "                print(\"Error in checking answer:\", result)\n",
    "                break\n",
    "\n",
    "            is_correct = result.get(\"result\") == \"correct\"\n",
    "            print(\"is_correct:\", is_correct)\n",
    "            if is_correct:\n",
    "                print(\"Correct answer! Moving to the next question.\")\n",
    "                break\n",
    "            else:\n",
    "                attempt += 1\n",
    "                if attempt < 3:\n",
    "                    print(\"Incorrect. Try again.\")\n",
    "                    # print(tutor_with_guidance(question, expected_answer, user_answer))\n",
    "                else:\n",
    "                    print(\"You've used all attempts. The correct answer is:\", expected_answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    student_question = input(\"What is your question? \")\n",
    "    if student_question.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        \n",
    "\n",
    "    print(student_question)\n",
    "    socratic_tutor(student_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has been estimated that it will take 10 men 6 days to complete a certain task. Find the number of days it will take 8 men to complete a job which is double that task.\n",
      "Student Question: It has been estimated that it will take 10 men 6 days to complete a certain task. Find the number of days it will take 8 men to complete a job which is double that task.\n",
      "Questions and Answers: [{'question': 'If 10 men take 6 days to complete a task, how many man-days are required for that task?', 'answer': '60 man-days (10 men * 6 days)'}, {'question': 'The new task is double the size of the original. How many man-days are required for the new task?', 'answer': '120 man-days (60 man-days * 2)'}, {'question': 'If you have 8 men and the task requires 120 man-days, how long will it take to complete the task?', 'answer': '15 days (120 man-days / 8 men)'}]\n",
      "Follow-up Question:  Good work so far! Now, consider this: How do you think we can figure out the total man-days needed to finish the task with your thought process.\n",
      "Expected Answer: 60 man-days (10 men * 6 days)\n",
      "50vdays\n",
      "{'result': 'incorrect'}\n",
      "is_correct: False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(student_question)\n\u001b[0;32m---> 59\u001b[0m \u001b[43msocratic_tutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_question\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 48\u001b[0m, in \u001b[0;36msocratic_tutor\u001b[0;34m(student_question)\u001b[0m\n\u001b[1;32m     45\u001b[0m attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# print(\"Incorrect. Try again.\")\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtutor_with_guidance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_answer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve used all attempts. The correct answer is:\u001b[39m\u001b[38;5;124m\"\u001b[39m, expected_answer)\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mtutor_with_guidance\u001b[0;34m(correct_answer, student_answer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtutor_with_guidance\u001b[39m(correct_answer, student_answer):\n\u001b[1;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    The correct answer is: '{correct_answer}'. The student's answer is: '{student_answer} which is incorrect'.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Based on the student's answer and its correctness, provide steps to get the correct answer.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Use a friendly, encouraging tone in your responses. Make sure to keep your response in short.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     )\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39m\u001b[43mquestion\u001b[49m, correct_answer\u001b[38;5;241m=\u001b[39mcorrect_answer, student_answer\u001b[38;5;241m=\u001b[39mstudent_answer)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_response_learnlm(prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "def socratic_tutor(student_question):\n",
    "    print(\"Student Question:\", student_question)\n",
    "\n",
    "    # Generate follow-up questions and expected answers\n",
    "    followup_qa = generate_followup_question(student_question)\n",
    "    if isinstance(followup_qa, str):\n",
    "        print(\"Error in generating follow-up questions:\", followup_qa)\n",
    "        return\n",
    "\n",
    "    questions_and_answers = followup_qa.get(\"questions_and_answers\", [])\n",
    "    print(\"Questions and Answers:\", questions_and_answers)\n",
    "    if not questions_and_answers:\n",
    "        print(\"No follow-up questions generated. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for item in questions_and_answers:\n",
    "        question = item.get(\"question\")\n",
    "        expected_answer = item.get(\"answer\")\n",
    "\n",
    "        if not question or not expected_answer:\n",
    "            print(\"Invalid question-answer pair. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Ask the question in a tutor tone\n",
    "        tutor_question = ask_question_in_tutor_tone(question)\n",
    "        print(\"Follow-up Question:\", tutor_question)\n",
    "        print(\"Expected Answer:\", expected_answer)\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < 3:\n",
    "            user_answer = input(\"Your Answer: \")\n",
    "            print(user_answer)\n",
    "            # Check answer correctness\n",
    "            result = check_answer_prompt(question, expected_answer, user_answer)\n",
    "            if isinstance(result, str):\n",
    "                print(\"Error in checking answer:\", result)\n",
    "                break\n",
    "\n",
    "            is_correct = result.get(\"result\") == \"correct\"\n",
    "            print(\"is_correct:\", is_correct)\n",
    "            if is_correct:\n",
    "                print(\"Correct answer! Moving to the next question.\")\n",
    "                break\n",
    "            else:\n",
    "                attempt += 1\n",
    "                if attempt < 3:\n",
    "                    # print(\"Incorrect. Try again.\")\n",
    "                    print(tutor_with_guidance(expected_answer, user_answer))\n",
    "                else:\n",
    "                    print(\"You've used all attempts. The correct answer is:\", expected_answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    student_question = input(\"What is your question? \")\n",
    "    if student_question.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        \n",
    "\n",
    "    print(student_question)\n",
    "    socratic_tutor(student_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'HumanMessage' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from openai import OpenAI\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    current_question: str\n",
    "    correct_answer: str\n",
    "    attempts: int\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# OpenRouterModel for LLM interactions\n",
    "class OpenRouterModel:\n",
    "    def __init__(self, model_name: str, api_key: str):\n",
    "        self.base_url = \"https://openrouter.ai/api/v1\"\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key)\n",
    "\n",
    "    def invoke(self, messages: list):\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "# Initialize OpenRouter model\n",
    "openrouter_model = OpenRouterModel(\n",
    "    model_name=\"microsoft/phi-3-mini-128k-instruct:free\",\n",
    "    api_key=\"sk-your-api-key\"  # Replace with your actual API key\n",
    ")\n",
    "\n",
    "# Functions for the Socratic Tutor\n",
    "def generate_followup(state: State):\n",
    "    prompt = (\n",
    "        f\"The student asked: '{state['messages'][0]['content']}'. Generate a follow-up question, \"\n",
    "        f\"the correct answer, and a Socratic explanation to guide the student.\"\n",
    "    )\n",
    "    response = openrouter_model.invoke([{\"role\": \"system\", \"content\": prompt}])\n",
    "    question, correct_answer, explanation = response.split(\"||\")  # Assuming delimited response\n",
    "    state[\"current_question\"] = question.strip()\n",
    "    state[\"correct_answer\"] = correct_answer.strip()\n",
    "    state[\"attempts\"] = 0\n",
    "    return state\n",
    "\n",
    "def ask_followup(state: State):\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": state[\"current_question\"]})\n",
    "    return state\n",
    "\n",
    "def check_answer(state: State):\n",
    "    user_answer = state[\"messages\"][-1][\"content\"]\n",
    "    prompt = (\n",
    "        f\"The follow-up question was: '{state['current_question']}'. The correct answer is \"\n",
    "        f\"'{state['correct_answer']}'. Did the student answer correctly? \"\n",
    "        f\"Student's answer: '{user_answer}'.\"\n",
    "    )\n",
    "    response = openrouter_model.invoke([{\"role\": \"system\", \"content\": prompt}])\n",
    "    return response.lower().strip() == \"yes\"\n",
    "\n",
    "def socratic_guidance(state: State):\n",
    "    user_answer = state[\"messages\"][-1][\"content\"]\n",
    "    prompt = (\n",
    "        f\"The student answered incorrectly to the question: '{state['current_question']}'. \"\n",
    "        f\"Their answer was: '{user_answer}'. Provide Socratic encouragement and guidance to help them.\"\n",
    "    )\n",
    "    response = openrouter_model.invoke([{\"role\": \"system\", \"content\": prompt}])\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "    return state\n",
    "\n",
    "def socratic_tutor(state: State):\n",
    "    if state[\"attempts\"] >= 3:\n",
    "        state[\"messages\"].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"The correct answer is: {state['correct_answer']}. Let's move on to the next question.\"\n",
    "        })\n",
    "        return generate_followup(state)\n",
    "\n",
    "    if check_answer(state):\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"That's correct! Well done.\"})\n",
    "        return generate_followup(state)\n",
    "\n",
    "    state[\"attempts\"] += 1\n",
    "    return socratic_guidance(state)\n",
    "\n",
    "# Graph construction\n",
    "graph_builder.add_node(\"generate_followup\", generate_followup)\n",
    "graph_builder.add_node(\"ask_followup\", ask_followup)\n",
    "graph_builder.add_node(\"socratic_tutor\", socratic_tutor)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_followup\")\n",
    "graph_builder.add_edge(\"generate_followup\", \"ask_followup\")\n",
    "graph_builder.add_edge(\"ask_followup\", \"socratic_tutor\")\n",
    "graph_builder.add_edge(\"socratic_tutor\", \"ask_followup\")\n",
    "graph_builder.add_edge(\"socratic_tutor\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": user_input}],\n",
    "        \"current_question\": \"\",\n",
    "        \"correct_answer\": \"\",\n",
    "        \"attempts\": 0\n",
    "    }):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1][\"content\"])\n",
    "\n",
    "# Run Socratic Tutor\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"Student: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
